import numpy as np
import torch
import logging
from dataclasses import dataclass, field
from typing import Dict, Any

from lerobot.robots.robot import Robot
from lerobot.robots.config import RobotConfig
from lerobot.cameras.configs import CameraConfig
from lerobot.cameras.opencv import OpenCVCamera

try:
    from lerobot.robots.mkrobot.follower_mkarm import MKFollower, MKFollowerConfig 
except ImportError:
    # å…è®¸åœ¨æ²¡æœ‰åº•å±‚åº“çš„æœºå™¨ä¸Šè¢«å¯¼å…¥ï¼ˆä¸»è¦é˜²æŠ¥é”™ï¼Œå®é™…è¿è¡Œè¿˜æ˜¯éœ€è¦çš„ï¼‰
    MKFollower = None
    MKFollowerConfig = None

logger = logging.getLogger(__name__)

# --- ç¡¬ä»¶æ–¹å‘ä¿®æ­£ ---
# Sim (URDF) <-> Real (Motor)
HARDWARE_DIR = np.array([-1.0, 1.0, -1.0, -1.0, -1.0, -1.0]) # å‰6è½´

# --- ğŸ›¡ï¸ å®‰å…¨é…ç½®ï¼šç‰©ç†å…³èŠ‚é™ä½ (å•ä½: å¼§åº¦) ---
# è¯·æ ¹æ®æ‚¨çš„ dk2.SLDASM.urdf æ–‡ä»¶ä¸­çš„ limit lower/upper è¿›è¡Œæ ¸å¯¹ä¿®æ­£
# è¿™é‡Œæä¾›çš„æ˜¯ä¸€ç»„ç›¸å¯¹å®‰å…¨çš„é»˜è®¤å€¼
JOINT_LIMITS = {
    # å…³èŠ‚ç´¢å¼•: (æœ€å°å¼§åº¦, æœ€å¤§å¼§åº¦)
    0: (-3.0, 3.0),  # Joint 1: åº•åº§æ—‹è½¬ (é€šå¸¸èŒƒå›´å¾ˆå¤§)
    1: (0.0, 3.0),  # Joint 2: å¤§è‡‚ (æ³¨æ„é¿å…æ’åœ°)
    2: (0.0, 3.0),  # Joint 3: è‚˜éƒ¨
    3: (-1.7, 1.2),  # Joint 4: è…•éƒ¨æ—‹è½¬
    4: (-0.4, 0.4),  # Joint 5: è…•éƒ¨å¼¯æ›²
    5: (-2.0, 2.0),  # Joint 6: æ³•å…°æ—‹è½¬
}

# # çœŸå®æœºæ¢°è‡‚çš„ç‰©ç†é™ä½ (ç”¨äºå‘é€æŒ‡ä»¤å‰çš„å®‰å…¨æˆªæ–­)
# REAL_JOINT_LIMITS = {
#     "joint_1": [-3.0, 3.0],
#     "joint_2": [-0.3, 3.0],
#     "joint_3": [0.0, 3.0],   # æ³¨æ„ï¼šè¿™æ˜¯æ­£å€¼åŒºé—´
#     "joint_4": [-1.7, 1.2],
#     "joint_5": [-0.4, 0.4],  # èŒƒå›´è¾ƒçª„
#     "joint_6": [-2.0, 2.0]
# }

class MKBusAdapter:
    """
    ä¼ªè£…æˆ DynamixelBusï¼Œä¸º gym_manipulator æä¾› sync_read/write æ¥å£ã€‚
    åŒæ—¶ç¡®ä¿å¤ä½æ“ä½œç»è¿‡ MKRobot çš„åæ ‡è½¬æ¢ï¼Œä¿è¯æ–¹å‘å®‰å…¨ã€‚
    """
    def __init__(self, mk_robot):
        self.mk_robot = mk_robot # æŒæœ‰ MKRobot å®ä¾‹ä»¥ä¾¿è°ƒç”¨å…¶ send_action/get_observation
        self.names = ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"]

    @property
    def motors(self):
        # è¿”å›ç”µæœºå­—å…¸ï¼Œç”¨äºè·å–é”®ååˆ—è¡¨
        return self.mk_robot.robot.motors

    def sync_read(self, prop):
        if prop == "Present_Position":
            # ä½¿ç”¨ MKRobot.get_observation è·å–ç»è¿‡ Sim åæ ‡è½¬æ¢åçš„çŠ¶æ€
            obs = self.mk_robot.get_observation()
            state = obs['observation.state'].cpu().numpy()
            
            # å°†æ•°ç»„é‡æ–°æ˜ å°„å›å­—å…¸ {joint_name: value}
            return {name: float(val) for name, val in zip(self.names, state)}
        return {}

    def sync_write(self, prop, values):
        if prop == "Goal_Position":
            # values æ˜¯ {joint_name: val} (Sim åæ ‡ç³»)
            # è½¬æ¢ä¸ºæ•°ç»„å¹¶è°ƒç”¨ MKRobot.send_action (å®ƒä¼šè‡ªåŠ¨å¤„ç† Sim->Real è½¬æ¢)
            target = np.zeros(7, dtype=np.float32)
            for i, name in enumerate(self.names):
                if name in values:
                    target[i] = values[name]
            
            self.mk_robot.send_action(target)

@RobotConfig.register_subclass("mk_robot")
@dataclass
class MKRobotConfig(RobotConfig):
    type: str = "mk_robot"
    port: str = "/dev/ttyACM0"
    joint_velocity_scaling: float = 1.0
    # 0.15 rad â‰ˆ 8.6åº¦ã€‚åœ¨30Hzä¸‹å…è®¸æœ€å¤§è§’é€Ÿåº¦çº¦ 4.5 rad/sã€‚
    # è¿™æ—¢èƒ½è·Ÿä¸Š Reset æŒ‡ä»¤ï¼Œåˆèƒ½é˜²æ­¢ RL ç­–ç•¥è¾“å‡º 3.14 æ—¶çš„é£è½¦äº‹æ•…ã€‚
    max_step_rad: float = 0.15
    cameras: dict[str, CameraConfig] = field(default_factory=dict)

class MKRobot(Robot):
    config_class = MKRobotConfig
    name = "mk_robot"

    def __init__(self, config: MKRobotConfig):
        super().__init__(config)
        self.config = config
        
        #æ‰‹åŠ¨åˆå§‹åŒ–ç›¸æœºåˆ—è¡¨
        self.cameras = {}
        for name, cam_config in config.cameras.items():
            # è¿™é‡Œçš„ cam_config å·²ç»æ˜¯é€šè¿‡ draccus è§£æå¥½çš„é…ç½®å¯¹è±¡
            if cam_config.type == "opencv":
                self.cameras[name] = OpenCVCamera(cam_config)
            else:
                logger.warning(f"âš ï¸ MKRobot ç›®å‰ä»…æ˜¾å¼æ”¯æŒ 'opencv' ç±»å‹ç›¸æœºï¼Œè·³è¿‡: {name} ({cam_config.type})")

        if MKFollowerConfig is None:
            raise ImportError("Could not import follower_mkarm. Please ensure it is in the python path.")

        # åˆå§‹åŒ–åº•å±‚é©±åŠ¨
        self.follower_config = MKFollowerConfig(
            port=config.port,
            joint_velocity_scaling=config.joint_velocity_scaling,
            disable_torque_on_disconnect=True
        )
        self.robot = MKFollower(self.follower_config)
        self.is_connected_flag = False

        self._bus_adapter = MKBusAdapter(self)
        # å®‰å…¨ç›¸å…³ï¼šè®°å½•ä¸Šä¸€æ¬¡çš„ç›®æ ‡ä½ç½®ï¼Œç”¨äºå¹³æ»‘å¤„ç†
        self.last_target_joints = None

    def connect(self):
        if not self.is_connected_flag:
            logger.info(f"ğŸ”— MKRobot: Connecting to {self.config.port}...")
            self.robot.connect()
            #è¿æ¥æ‰€æœ‰æ‘„åƒå¤´
            for name, cam in self.cameras.items():
                logger.info(f"ğŸ“· Connecting camera: {name}")
                cam.connect()

            self.is_connected_flag = True

            # è¿æ¥æ—¶è¯»å–å½“å‰ä½ç½®ä½œä¸ºåˆå§‹ç›®æ ‡ï¼Œé˜²æ­¢ä¸€ä¸Šç”µå°±è·³å˜
            init_obs = self.robot.get_observation()
            if init_obs:
                q_real = np.zeros(6)
                for i in range(6):
                    q_real[i] = init_obs.get(f'joint_{i+1}.pos', 0)
                self.last_target_joints = q_real

            logger.info("âœ… MKRobot: Connected!")

    def disconnect(self):
        if self.is_connected_flag:
            #æ–­å¼€æ‰€æœ‰æ‘„åƒå¤´
            for name, cam in self.cameras.items():
                cam.disconnect()

            self.robot.disconnect()
            self.is_connected_flag = False

    @property
    def is_connected(self):
        return self.is_connected_flag

    @property
    def bus(self):
        # è¿”å›é€‚é…å™¨è€Œä¸æ˜¯åº•å±‚é©±åŠ¨
        return self._bus_adapter

    @property
    def is_calibrated(self):
        """å‡å®šç”µæœºå·²æ ¡å‡†å¥½ï¼Œæˆ–è€…ä¸éœ€è¦æ ¡å‡†"""
        return True

    def calibrate(self):
        """æ ¡å‡†æµç¨‹ï¼ˆç©ºå®ç°ï¼‰"""
        pass

    def configure(self, config):
        """é…ç½®æµç¨‹ï¼ˆç©ºå®ç°ï¼‰"""
        pass

    @property
    def action_features(self):
        """å®šä¹‰åŠ¨ä½œç©ºé—´çš„æ•°æ®ç»“æ„"""
        return {
            "action": {
                "dtype": "float32",
                "shape": (7,),
                "names": ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"],
            }
        }

    @property
    def observation_features(self):
        """å®šä¹‰è§‚æµ‹ç©ºé—´çš„æ•°æ®ç»“æ„"""
        return {
            "observation.state": {
                "dtype": "float32",
                "shape": (7,),
                "names": ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"],
            },
            # å¦‚æœä½ ä¹Ÿè¿”å›é€Ÿåº¦ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸Š
            # "observation.velocity": { ... }
        }

    def capture_images(self) -> Dict[str, Any]:
        """è¯»å–æ‰€æœ‰å·²è¿æ¥æ‘„åƒå¤´çš„å›¾åƒ"""
        images = {}
        for name, camera in self.cameras.items():
            # ä¼˜å…ˆå°è¯•å¼‚æ­¥è¯»å–ä»¥æé«˜å¸§ç‡ï¼Œå¦‚æœä¸æ”¯æŒåˆ™ä½¿ç”¨æ™®é€šè¯»å–
            # if hasattr(camera, "async_read"):
            #     images[name] = camera.async_read()
            # else:
            images[name] = camera.read()
        return images

    # =========================================================
    # ğŸ›¡ï¸ æ ¸å¿ƒå®‰å…¨é€»è¾‘ï¼šé€Ÿåº¦å¹³æ»‘ + ç»å¯¹ä½ç½®ç¡¬é™ä½
    # =========================================================

    def send_action(self, action: torch.Tensor) -> torch.Tensor:
        if not self.is_connected: return action

        # 1. æ ¼å¼è½¬æ¢
        if isinstance(action, torch.Tensor):
            q_sim_target = action.cpu().numpy()
        else:
            q_sim_target = action

        # 2. æ˜ å°„åˆ° Real åæ ‡ç³»
        q_real_target = q_sim_target[:6] * HARDWARE_DIR
        g_real_target = np.clip(q_sim_target[6], 0.0, 1.0)

        # 3. è¯»å–å½“å‰çœŸå®ä½ç½®
        current_obs = self.robot.get_observation()
        q_real_current = np.zeros(6)
        for i in range(6):
            q_real_current[i] = current_obs.get(f'joint_{i+1}.pos', 0)

        # ---------------------------------------------------
        # ğŸ›¡ï¸ ä¼˜åŒ–åçš„å®‰å…¨é€»è¾‘: å…ˆä½ç½®æˆªæ–­ï¼Œå†é€Ÿåº¦æˆªæ–­
        # ---------------------------------------------------
        
        q_real_safe = np.zeros(6)
        
        for i in range(6):
            # A. è·å–é™ä½
            min_lim, max_lim = JOINT_LIMITS.get(i, (-3.14, 3.14))
            
            # B. ã€å…³é”®ã€‘å…ˆå°†ç›®æ ‡å¼ºè¡Œé™åˆ¶åœ¨ç‰©ç†é™ä½å†…
            # è¿™æ ·æ— è®º Policy æƒ³è¦å»å¤šè¿œçš„åœ°æ–¹ï¼Œæˆ‘ä»¬åªæŠŠå®ƒå½“åšæƒ³è¦å»è¾¹ç•Œ
            target_clamped = np.clip(q_real_target[i], min_lim, max_lim)
            
            # C. è®¡ç®— çœŸå®ä½ç½® -> è¾¹ç•Œ çš„è·ç¦»
            delta = target_clamped - q_real_current[i]
            
            # D. å¯¹è¿™ä¸ªè·ç¦»è¿›è¡Œé™é€Ÿ (å¹³æ»‘å¤„ç†)
            # å³ä½¿ current åœ¨è¾¹ç•Œå¤– (ä¾‹å¦‚ 2.0, limit 1.6), delta æ˜¯ -0.4
            # ä¹Ÿä¼šè¢«å¹³æ»‘é™åˆ¶ä¸º -0.15, ä»è€Œå®‰å…¨åœ°æ…¢æ…¢é€€å›ï¼Œè€Œä¸æ˜¯å‰§çƒˆè·³å˜
            max_step = self.config.max_step_rad
            delta_safe = np.clip(delta, -max_step, max_step)
            
            # E. æœ€ç»ˆæŒ‡ä»¤
            q_real_safe[i] = q_real_current[i] + delta_safe

        # 4. å‘é€æœ€ç»ˆçš„å®‰å…¨æŒ‡ä»¤
        command = {
            "joint_1.pos": q_real_safe[0],
            "joint_2.pos": q_real_safe[1],
            "joint_3.pos": q_real_safe[2],
            "joint_4.pos": q_real_safe[3],
            "joint_5.pos": q_real_safe[4],
            "joint_6.pos": q_real_safe[5],
            "gripper.pos": g_real_target
        }
        self.robot.send_action(command)
        
        return action

    # # =========================================================
    # # ğŸ•¹ï¸ æ ¸å¿ƒæ”¶å‘é€»è¾‘
    # # =========================================================

    # def send_action(self, action: torch.Tensor) -> torch.Tensor:
    #     """
    #     æ¥æ”¶ Sim åæ ‡ç³»åŠ¨ä½œ (URDF) -> è½¬æ¢ä¸º Real åŠ¨ä½œ -> å‘é€
    #     """
    #     if not self.is_connected: return action

    #     # 1. è½¬æ¢æ ¼å¼ (Tensor -> Numpy)
    #     if isinstance(action, torch.Tensor):
    #         q_sim = action.cpu().numpy()
    #     else:
    #         q_sim = action

    #     # 2. å…³èŠ‚è§’åº¦æ˜ å°„ (Sim -> Real)
    #     # å‰6è½´ä¹˜ç³»æ•°
    #     q_real_target = q_sim[:6] * HARDWARE_DIR
        
    #     # 3. å¤¹çˆªæ˜ å°„ (Sim -> Real)
    #     # å‡è®¾ Teleop è¾“å‡ºçš„æ˜¯å½’ä¸€åŒ– 0.0(Open)~1.0(Close)
    #     # å¦‚æœä½ çš„çœŸæœºæ˜¯ 1.0=Close, 0.0=Openï¼Œåˆ™ç›´æ¥ç”¨
    #     g_real = np.clip(q_sim[6], 0.0, 1.0)

    #     # --- ğŸ›¡ï¸ å®‰å…¨é™é€Ÿæ ¸å¿ƒä»£ç  START ---
    #     # è¯»å–å½“å‰çœŸå®çš„ç”µæœºä½ç½®
    #     current_obs = self.robot.get_observation()
    #     q_real_current = np.zeros(6)
    #     for i in range(6):
    #         q_real_current[i] = current_obs.get(f'joint_{i+1}.pos', 0)

    #     # è®¡ç®—è¿™ä¸€å¸§æƒ³ç§»åŠ¨çš„é‡ (Target - Current)
    #     delta = q_real_target - q_real_current
        
    #     # å¼ºåˆ¶æˆªæ–­ï¼šæ¯å¸§æœ€å¤§åªèƒ½ç§»åŠ¨ config.max_step_rad (é»˜è®¤0.05)
    #     # è¿™æ ·å³ä½¿ç­–ç•¥è¾“å‡º 3.14ï¼Œä¹Ÿåªä¼šç§»åŠ¨ 0.05ï¼Œå˜æˆå¹³æ»‘çš„è¿åŠ¨
    #     max_step = self.config.max_step_rad
    #     delta_clipped = np.clip(delta, -max_step, max_step)
        
    #     # è®¡ç®—å‡ºå®é™…å‘é€ç»™ç”µæœºçš„å®‰å…¨ç›®æ ‡
    #     q_real_safe = q_real_current + delta_clipped
        
    #     # æ›´æ–° gripper (å¤¹çˆªé€šå¸¸ä¸éœ€è¦å¹³æ»‘ï¼Œæˆ–è€…å¯ä»¥ç»™å¤§ä¸€ç‚¹çš„é˜ˆå€¼)
    #     # è¿™é‡Œç›´æ¥é€šè¿‡
    #     # --- ğŸ›¡ï¸ å®‰å…¨é™é€Ÿæ ¸å¿ƒä»£ç  END ---


    #     # 4. ç»„è£…å­—å…¸å‘é€
    #     command = {
    #         "joint_1.pos": q_real_safe[0],
    #         "joint_2.pos": q_real_safe[1],
    #         "joint_3.pos": q_real_safe[2],
    #         "joint_4.pos": q_real_safe[3],
    #         "joint_5.pos": q_real_safe[4],
    #         "joint_6.pos": q_real_safe[5],
    #         "gripper.pos": g_real
    #     }
    #     self.robot.send_action(command)
        
    #     return action

    def get_observation(self) -> Dict[str, Any]:
        """
        è¯»å– Real çŠ¶æ€ -> è½¬æ¢ä¸º Sim åæ ‡ç³» (URDF) -> è¿”å›
        """
        if not self.is_connected:
            # è¿”å›ç©ºæˆ–é›¶å€¼ï¼Œé˜²æ­¢å´©æºƒ
            return {"observation.state": torch.zeros(7)}

        raw_obs = self.robot.get_observation()
        
        # 1. è§£æå¹¶è½¬æ¢å…³èŠ‚ (Real -> Sim)
        q_sim = np.zeros(7)
        q_sim[0] = raw_obs.get('joint_1.pos', 0) * HARDWARE_DIR[0]
        q_sim[1] = raw_obs.get('joint_2.pos', 0) * HARDWARE_DIR[1]
        q_sim[2] = raw_obs.get('joint_3.pos', 0) * HARDWARE_DIR[2]
        q_sim[3] = raw_obs.get('joint_4.pos', 0) * HARDWARE_DIR[3]
        q_sim[4] = raw_obs.get('joint_5.pos', 0) * HARDWARE_DIR[4]
        q_sim[5] = raw_obs.get('joint_6.pos', 0) * HARDWARE_DIR[5]

        # 2. è§£æå¹¶è½¬æ¢å¤¹çˆª (Real -> Sim)
        # å‡è®¾çœŸæœºè¿”å› 0.0~1.0
        g_real = raw_obs.get('gripper.pos', 0)
        q_sim[6] = g_real
        
        images = self.capture_images()

        # å¿…é¡»åŒ…å«: 
        #   - ç‹¬ç«‹çš„ joint_x.pos (ä¾› GymEnv è¯»å–)
        #   - å›¾åƒ (ä¾› GymEnv è¯»å–)
        #   - observation.state (ä¾› Policy ä½¿ç”¨)
        
        obs_dict = {
            "observation.state": torch.from_numpy(q_sim).float(),
            # æ˜¾å¼å¡«å…¥ GymEnv éœ€è¦çš„é”®å
            "joint_1.pos": q_sim[0],
            "joint_2.pos": q_sim[1],
            "joint_3.pos": q_sim[2],
            "joint_4.pos": q_sim[3],
            "joint_5.pos": q_sim[4],
            "joint_6.pos": q_sim[5],
            "gripper.pos": q_sim[6],
        }

        # åˆå¹¶å›¾åƒæ•°æ®åˆ°å­—å…¸ä¸­
        obs_dict.update(images)

        return obs_dict