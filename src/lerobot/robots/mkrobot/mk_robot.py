import numpy as np
import torch
import logging
from dataclasses import dataclass, field
from typing import Dict, Any

from lerobot.robots.robot import Robot
from lerobot.robots.config import RobotConfig
from lerobot.cameras.configs import CameraConfig
from lerobot.cameras.opencv import OpenCVCamera

try:
    from lerobot.robots.mkrobot.follower_mkarm import MKFollower, MKFollowerConfig 
except ImportError:
    # å…è®¸åœ¨æ²¡æœ‰åº•å±‚åº“çš„æœºå™¨ä¸Šè¢«å¯¼å…¥ï¼ˆä¸»è¦é˜²æŠ¥é”™ï¼Œå®é™…è¿è¡Œè¿˜æ˜¯éœ€è¦çš„ï¼‰
    MKFollower = None
    MKFollowerConfig = None

logger = logging.getLogger(__name__)

# --- ç¡¬ä»¶æ–¹å‘ä¿®æ­£ ---
# Sim (URDF) <-> Real (Motor)
HARDWARE_DIR = np.array([-1.0, 1.0, -1.0, -1.0, -1.0, -1.0]) # å‰6è½´

class MKBusAdapter:
    """
    ä¼ªè£…æˆ DynamixelBusï¼Œä¸º gym_manipulator æä¾› sync_read/write æ¥å£ã€‚
    åŒæ—¶ç¡®ä¿å¤ä½æ“ä½œç»è¿‡ MKRobot çš„åæ ‡è½¬æ¢ï¼Œä¿è¯æ–¹å‘å®‰å…¨ã€‚
    """
    def __init__(self, mk_robot):
        self.mk_robot = mk_robot # æŒæœ‰ MKRobot å®ä¾‹ä»¥ä¾¿è°ƒç”¨å…¶ send_action/get_observation
        self.names = ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"]

    @property
    def motors(self):
        # è¿”å›ç”µæœºå­—å…¸ï¼Œç”¨äºè·å–é”®ååˆ—è¡¨
        return self.mk_robot.robot.motors

    def sync_read(self, prop):
        if prop == "Present_Position":
            # ä½¿ç”¨ MKRobot.get_observation è·å–ç»è¿‡ Sim åæ ‡è½¬æ¢åçš„çŠ¶æ€
            obs = self.mk_robot.get_observation()
            state = obs['observation.state'].cpu().numpy()
            
            # å°†æ•°ç»„é‡æ–°æ˜ å°„å›å­—å…¸ {joint_name: value}
            return {name: float(val) for name, val in zip(self.names, state)}
        return {}

    def sync_write(self, prop, values):
        if prop == "Goal_Position":
            # values æ˜¯ {joint_name: val} (Sim åæ ‡ç³»)
            # è½¬æ¢ä¸ºæ•°ç»„å¹¶è°ƒç”¨ MKRobot.send_action (å®ƒä¼šè‡ªåŠ¨å¤„ç† Sim->Real è½¬æ¢)
            target = np.zeros(7, dtype=np.float32)
            for i, name in enumerate(self.names):
                if name in values:
                    target[i] = values[name]
            
            self.mk_robot.send_action(target)

@RobotConfig.register_subclass("mk_robot")
@dataclass
class MKRobotConfig(RobotConfig):
    type: str = "mk_robot"
    port: str = "/dev/ttyACM0"
    joint_velocity_scaling: float = 1.0
    cameras: dict[str, CameraConfig] = field(default_factory=dict)

class MKRobot(Robot):
    config_class = MKRobotConfig
    name = "mk_robot"

    def __init__(self, config: MKRobotConfig):
        super().__init__(config)
        self.config = config
        
        #æ‰‹åŠ¨åˆå§‹åŒ–ç›¸æœºåˆ—è¡¨
        self.cameras = {}
        for name, cam_config in config.cameras.items():
            # è¿™é‡Œçš„ cam_config å·²ç»æ˜¯é€šè¿‡ draccus è§£æå¥½çš„é…ç½®å¯¹è±¡
            if cam_config.type == "opencv":
                self.cameras[name] = OpenCVCamera(cam_config)
            else:
                logger.warning(f"âš ï¸ MKRobot ç›®å‰ä»…æ˜¾å¼æ”¯æŒ 'opencv' ç±»å‹ç›¸æœºï¼Œè·³è¿‡: {name} ({cam_config.type})")

        if MKFollowerConfig is None:
            raise ImportError("Could not import follower_mkarm. Please ensure it is in the python path.")

        # åˆå§‹åŒ–åº•å±‚é©±åŠ¨
        self.follower_config = MKFollowerConfig(
            port=config.port,
            joint_velocity_scaling=config.joint_velocity_scaling,
            disable_torque_on_disconnect=True
        )
        self.robot = MKFollower(self.follower_config)
        self.is_connected_flag = False

        self._bus_adapter = MKBusAdapter(self)

    def connect(self):
        if not self.is_connected_flag:
            logger.info(f"ğŸ”— MKRobot: Connecting to {self.config.port}...")
            self.robot.connect()
            #è¿æ¥æ‰€æœ‰æ‘„åƒå¤´
            for name, cam in self.cameras.items():
                logger.info(f"ğŸ“· Connecting camera: {name}")
                cam.connect()

            self.is_connected_flag = True
            logger.info("âœ… MKRobot: Connected!")

    def disconnect(self):
        if self.is_connected_flag:
            #æ–­å¼€æ‰€æœ‰æ‘„åƒå¤´
            for name, cam in self.cameras.items():
                cam.disconnect()

            self.robot.disconnect()
            self.is_connected_flag = False

    @property
    def is_connected(self):
        return self.is_connected_flag

    @property
    def bus(self):
        # è¿”å›é€‚é…å™¨è€Œä¸æ˜¯åº•å±‚é©±åŠ¨
        return self._bus_adapter

    @property
    def is_calibrated(self):
        """å‡å®šç”µæœºå·²æ ¡å‡†å¥½ï¼Œæˆ–è€…ä¸éœ€è¦æ ¡å‡†"""
        return True

    def calibrate(self):
        """æ ¡å‡†æµç¨‹ï¼ˆç©ºå®ç°ï¼‰"""
        pass

    def configure(self, config):
        """é…ç½®æµç¨‹ï¼ˆç©ºå®ç°ï¼‰"""
        pass

    @property
    def action_features(self):
        """å®šä¹‰åŠ¨ä½œç©ºé—´çš„æ•°æ®ç»“æ„"""
        return {
            "action": {
                "dtype": "float32",
                "shape": (7,),
                "names": ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"],
            }
        }

    @property
    def observation_features(self):
        """å®šä¹‰è§‚æµ‹ç©ºé—´çš„æ•°æ®ç»“æ„"""
        return {
            "observation.state": {
                "dtype": "float32",
                "shape": (7,),
                "names": ["joint_1", "joint_2", "joint_3", "joint_4", "joint_5", "joint_6", "gripper"],
            },
            # å¦‚æœä½ ä¹Ÿè¿”å›é€Ÿåº¦ï¼Œå¯ä»¥åœ¨è¿™é‡ŒåŠ ä¸Š
            # "observation.velocity": { ... }
        }

    def capture_images(self) -> Dict[str, Any]:
        """è¯»å–æ‰€æœ‰å·²è¿æ¥æ‘„åƒå¤´çš„å›¾åƒ"""
        images = {}
        for name, camera in self.cameras.items():
            # ä¼˜å…ˆå°è¯•å¼‚æ­¥è¯»å–ä»¥æé«˜å¸§ç‡ï¼Œå¦‚æœä¸æ”¯æŒåˆ™ä½¿ç”¨æ™®é€šè¯»å–
            if hasattr(camera, "async_read"):
                images[name] = camera.async_read()
            else:
                images[name] = camera.read()
        return images

    # =========================================================
    # ğŸ•¹ï¸ æ ¸å¿ƒæ”¶å‘é€»è¾‘
    # =========================================================

    def send_action(self, action: torch.Tensor) -> torch.Tensor:
        """
        æ¥æ”¶ Sim åæ ‡ç³»åŠ¨ä½œ (URDF) -> è½¬æ¢ä¸º Real åŠ¨ä½œ -> å‘é€
        """
        if not self.is_connected: return action

        # 1. è½¬æ¢æ ¼å¼ (Tensor -> Numpy)
        if isinstance(action, torch.Tensor):
            q_sim = action.cpu().numpy()
        else:
            q_sim = action

        # 2. å…³èŠ‚è§’åº¦æ˜ å°„ (Sim -> Real)
        # å‰6è½´ä¹˜ç³»æ•°
        q_real_joints = q_sim[:6] * HARDWARE_DIR
        
        # 3. å¤¹çˆªæ˜ å°„ (Sim -> Real)
        # å‡è®¾ Teleop è¾“å‡ºçš„æ˜¯å½’ä¸€åŒ– 0.0(Open)~1.0(Close)
        # å¦‚æœä½ çš„çœŸæœºæ˜¯ 1.0=Close, 0.0=Openï¼Œåˆ™ç›´æ¥ç”¨
        g_real = np.clip(q_sim[6], 0.0, 1.0)

        # 4. ç»„è£…å­—å…¸å‘é€
        command = {
            "joint_1.pos": q_real_joints[0],
            "joint_2.pos": q_real_joints[1],
            "joint_3.pos": q_real_joints[2],
            "joint_4.pos": q_real_joints[3],
            "joint_5.pos": q_real_joints[4],
            "joint_6.pos": q_real_joints[5],
            "gripper.pos": g_real
        }
        self.robot.send_action(command)
        
        return action

    def get_observation(self) -> Dict[str, Any]:
        """
        è¯»å– Real çŠ¶æ€ -> è½¬æ¢ä¸º Sim åæ ‡ç³» (URDF) -> è¿”å›
        """
        if not self.is_connected:
            # è¿”å›ç©ºæˆ–é›¶å€¼ï¼Œé˜²æ­¢å´©æºƒ
            return {"observation.state": torch.zeros(7)}

        raw_obs = self.robot.get_observation()
        
        # 1. è§£æå¹¶è½¬æ¢å…³èŠ‚ (Real -> Sim)
        q_sim = np.zeros(7)
        q_sim[0] = raw_obs.get('joint_1.pos', 0) * HARDWARE_DIR[0]
        q_sim[1] = raw_obs.get('joint_2.pos', 0) * HARDWARE_DIR[1]
        q_sim[2] = raw_obs.get('joint_3.pos', 0) * HARDWARE_DIR[2]
        q_sim[3] = raw_obs.get('joint_4.pos', 0) * HARDWARE_DIR[3]
        q_sim[4] = raw_obs.get('joint_5.pos', 0) * HARDWARE_DIR[4]
        q_sim[5] = raw_obs.get('joint_6.pos', 0) * HARDWARE_DIR[5]

        # 2. è§£æå¹¶è½¬æ¢å¤¹çˆª (Real -> Sim)
        # å‡è®¾çœŸæœºè¿”å› 0.0~1.0
        g_real = raw_obs.get('gripper.pos', 0)
        q_sim[6] = g_real
        
        images = self.capture_images()

        # å¿…é¡»åŒ…å«: 
        #   - ç‹¬ç«‹çš„ joint_x.pos (ä¾› GymEnv è¯»å–)
        #   - å›¾åƒ (ä¾› GymEnv è¯»å–)
        #   - observation.state (ä¾› Policy ä½¿ç”¨)
        
        obs_dict = {
            "observation.state": torch.from_numpy(q_sim).float(),
            # æ˜¾å¼å¡«å…¥ GymEnv éœ€è¦çš„é”®å
            "joint_1.pos": q_sim[0],
            "joint_2.pos": q_sim[1],
            "joint_3.pos": q_sim[2],
            "joint_4.pos": q_sim[3],
            "joint_5.pos": q_sim[4],
            "joint_6.pos": q_sim[5],
            "gripper.pos": q_sim[6],
        }

        # åˆå¹¶å›¾åƒæ•°æ®åˆ°å­—å…¸ä¸­
        obs_dict.update(images)

        return obs_dict